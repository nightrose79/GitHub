{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import lxml.etree as ET\n",
    "\n",
    "def parse_post(row):\n",
    "  \"\"\"\n",
    "  <row Id=\"1\" PostTypeId=\"1\" AcceptedAnswerId=\"15\"\n",
    "  CreationDate=\"2010-07-19T19:12:12.510\" Score=\"19\" ViewCount=\"1033\"\n",
    "  Body=\"&lt;p&gt;How should I elicit prior distributions from experts when\n",
    "  fitting a Bayesian model?&lt;/p&gt;&#xA;\" OwnerUserId=\"8\"\n",
    "  LastActivityDate=\"2010-09-15T21:08:26.077\" Title=\"Eliciting priors from\n",
    "  experts\" Tags=\"&lt;bayesian&gt;&lt;prior&gt;&lt;elicitatihttps://159.203.106.96:8889/notebooks/miniprojects/spark/data/allPosts/project_new.ipynb#on&gt;\"\n",
    "  AnswerCount=\"5\" CommentCount=\"1\" FavoriteCount=\"11\" />\n",
    "  \"\"\"\n",
    "\n",
    "  try:\n",
    "    if row.startswith(\"  <row \") and row.endswith(\"/>\"):\n",
    "      root = ET.fromstring(row)\n",
    "    else:\n",
    "      return None\n",
    "  except:\n",
    "    return None\n",
    "\n",
    "  return Post(root.attrib.get('Id', None),\n",
    "              root.attrib.get('PostTypeId', None),\n",
    "              root.attrib.get('AcceptedAnswerId', None),\n",
    "              root.attrib.get('CreationDate', None),\n",
    "              root.attrib.get('Score', None),\n",
    "              root.attrib.get('ViewCount', None),\n",
    "              root.attrib.get('Body', \"\"),\n",
    "              root.attrib.get('OwnerUserId', None),\n",
    "              root.attrib.get('LastActivityDate', None),\n",
    "              root.attrib.get('Title', \"\"),\n",
    "              root.attrib.get('Tags', \"\").strip(\"><\").split(\"><\"),\n",
    "              root.attrib.get('AnswerCount', None),\n",
    "              root.attrib.get('CommentCount', None),\n",
    "              root.attrib.get('FavoriteCount', None),\n",
    "             )\n",
    "\n",
    "class Post(object):\n",
    "  def __init__(self, post_id, post_type_id, accepted_answer_id, creation_date,\n",
    "               score, view_count, body, owner_user_id, last_activity_date,\n",
    "               title, tags, answer_count, comment_count, favorite_count):\n",
    "    self.post_id = self.process_int(post_id)\n",
    "    self.post_type_id = self.process_int(post_type_id)\n",
    "    self.accepted_answer_id = self.process_int(accepted_answer_id)\n",
    "    self.creation_date = self.process_time(creation_date)\n",
    "    self.score = self.process_int(score)\n",
    "    self.view_count = self.process_int(view_count)\n",
    "    self.body = body\n",
    "    self.owner_user_id = self.process_int(owner_user_id)\n",
    "    self.last_activity_date = self.process_time(last_activity_date)\n",
    "    self.title = title\n",
    "    self.tags = tags\n",
    "    self.answer_count = self.process_int(answer_count)\n",
    "    self.comment_count = self.process_int(comment_count)\n",
    "    self.favorite_count = self.process_int(favorite_count)\n",
    "\n",
    "  def process_int(self, field):\n",
    "    try:\n",
    "      return int(field)\n",
    "    except:\n",
    "      return None\n",
    "\n",
    "  def process_time(self, field):\n",
    "    try:\n",
    "      return datetime.strptime(field, \"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "    except:\n",
    "      return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local[*]\", \"temp\")\n",
    "print sc.version  # should be >= 1.5.1 for distributed matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def localpath(path):\n",
    "    return 'file://' + str(os.path.abspath(os.path.curdir)) + '/' + path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Basic wordcount\n",
    "lines = sc.textFile(localpath('part-*'))\n",
    "post=lines.map(parse_post).filter(lambda x:x is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108741"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '',\n",
       " 'Are two empirically estimated Markov chains statistically different?',\n",
       " '',\n",
       " 'Probability of winning a tournament',\n",
       " 'Is there a way to use cross validation to do variable/feature selection in R?',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post.map(lambda x: x.title).take(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
